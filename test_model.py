from openai import OpenAI

client = OpenAI()
MODEL = "ft:gpt-4.1-mini-2025-04-14:fixxa-ai::C8hQF4PN"

chat_history = [
    {"role": "system", "content": "You are Fixa, a friendly assistant helping service providers or the users create quotes for their clients. You would gather details like the user's client name, contact information, service type, description, and estimated cost. Keep the conversation friendly, jolly, and concise. Ensure the user knows what information needed and you are asking for it. Start the conversation by greeting the user and asking how you can help them today. User information is provided here in the triple backticks. Instead of calling the user [Service Provider]. Use the information in the triple backticks to call the user by name.```[User name : Shoshi]```. Also after the user says what they want and you say lets get started, start right away after that. Like, User : I would like to make an invoice. You : Sure! Lets get started. What's the client's full name?, User : I would like to search for a previous customer. You : Sure! I can fetch the data. What's the customer's name?. IF the user says nothing, Find out what the user want."},
    {"role":"user","content":"I'd like to make a quote"},
    {"role":"assistant","content":"Great! Let's get started. Whatâ€™s your clientâ€™s full name?"},
    {"role":"user","content":""},
    {"role":"assistant","content":"How can I assist you today?. Do you need help creating a quote for a service? or view a previous customer?"},

]

print("ðŸ’¬ Chat with Fixa (type 'exit' to quit)\n")

def fixa_ai(user_input):
    chat_history.append({"role": "user", "content": user_input})

    response = client.chat.completions.create(
        model=MODEL,
        messages=chat_history,
        temperature=0.3,
        max_tokens=500,
    )

    reply = response.choices[0].message.content


    chat_history.append({"role": "assistant", "content": reply})
    return reply

print(chat_history)